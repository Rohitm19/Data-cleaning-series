{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.1 Introduction to Addressing Data Entry Errors\n",
    "\n",
    "Data entry errors are one of the most common and persistent challenges in data management and analysis. These errors arise during the manual or automated input of data into a system and can significantly distort the accuracy and reliability of the data. Addressing data entry errors is a critical step in the data cleaning process, ensuring that datasets are both accurate and trustworthy for analysis, reporting, and decision-making.\n",
    "\n",
    "In any data-driven project, the quality of the data is paramount. Poor data quality, often resulting from entry errors, can lead to flawed analyses, misguided business decisions, and inefficiencies in operations. Therefore, identifying and correcting these errors is essential to maintain the integrity of the data and the insights derived from it. Addressing Data Entry Errors involves systematically detecting and correcting mistakes such as typos, incorrect data formats, inconsistencies, and inaccuracies that may have been introduced during the data entry process.\n",
    "\n",
    "Definition\n",
    "\n",
    "Data Entry Errors refer to mistakes or inaccuracies that occur during the process of entering data into a system. These errors can manifest in various forms, including typographical errors, transposed digits, incorrect units, and inconsistencies in data formatting. They can be introduced by human operators, automated systems, or during data migration from one system to another.\n",
    "\n",
    "Common types of data entry errors include:\n",
    "\n",
    "1. Typographical Errors (Typos): Simple mistakes made during manual data entry, such as misspellings or incorrect numbers.\n",
    "2. Transposition Errors: Errors where digits or characters are swapped, such as entering \"1234\" as \"1324.\"\n",
    "3. Incorrect Formatting: Data entered in the wrong format, such as dates entered as \"MM/DD/YYYY\" instead of \"DD/MM/YYYY.\"\n",
    "4. Unit Mismatches: Entering data with incorrect units, such as \"lbs\" instead of \"kg.\"\n",
    "5. Inconsistencies: Variations in how similar data is entered, such as \"NY\" for New York in one entry and \"New York\" in another.\n",
    "\n",
    "Objective\n",
    "\n",
    "The primary objective of addressing data entry errors is to ensure that the data is accurate, consistent, and reliable. This process is essential for maintaining the integrity of the dataset and ensuring that subsequent analyses and operations are based on correct and trustworthy data. By correcting these errors, we aim to:\n",
    "\n",
    "1. Enhance Data Quality: Improve the overall quality of the data, making it more reliable for analysis and decision-making.\n",
    "2. Ensure Consistency: Achieve uniformity in how data is recorded and represented across the dataset.\n",
    "3. Reduce Errors in Analysis: Minimize the risk of errors or biases in analysis that could arise from flawed data.\n",
    "4. Improve Decision-Making: Provide a solid foundation of accurate data for informed business or research decisions.\n",
    "5. Maintain Trust: Preserve trust in the data and the processes that rely on it by ensuring that data entry errors are promptly and effectively addressed.\n",
    "\n",
    "Importance\n",
    "\n",
    "Addressing data entry errors is crucial for several reasons:\n",
    "\n",
    "1. Data Accuracy: Ensuring that the data accurately reflects the reality it is intended to represent is fundamental for any analysis.\n",
    "2. Operational Efficiency: High-quality, error-free data reduces the need for rework and minimizes disruptions caused by inaccuracies in operational systems.\n",
    "3. Risk Mitigation: By correcting data entry errors, organizations can avoid potential risks associated with flawed data, such as incorrect financial reporting, compliance issues, or flawed strategic decisions.\n",
    "4. Improved Analysis: Accurate data allows for more precise and meaningful analysis, leading to better insights and outcomes.\n",
    "5. Cost Savings: Reducing the incidence of data entry errors can save significant time and resources that would otherwise be spent on rectifying mistakes later in the data processing pipeline.\n",
    "\n",
    "8.2 Techniques List and Definitions\n",
    "1. Standardizing Formats: Ensure consistency in the format of data entries.\n",
    "2. Correcting Typos: Identify and correct common typographical errors.\n",
    "3. Handling Inconsistent Data: Resolve discrepancies in data entries to maintain uniformity.\n",
    "4. Validation Checks: Implement rules to catch and correct data entry errors.\n",
    "5. Automated Data Correction: Use algorithms to automatically detect and correct data entry errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.2.1 Standardizing Formats\n",
    "\n",
    "Standardizing data formats involves ensuring that data entries follow a consistent format throughout the dataset. This is particularly important for fields like dates, phone numbers, and addresses, where variations in format can lead to inconsistencies and errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Product ID    Phone Number\n",
      "0           1  (123) 456-7890\n",
      "1           2  (123) 456-7890\n",
      "2           3  (123) 456-7890\n",
      "3           4  (123) 456-7890\n",
      "4           5  (123) 456-7890\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample Data\n",
    "data = {'Product ID': [1, 2, 3, 4, 5],\n",
    "        'Phone Number': ['123-456-7890', '(123) 456-7890', '123.456.7890', '1234567890', '123 456 7890']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Standardizing Phone Number Format\n",
    "df['Phone Number'] = df['Phone Number'].str.replace(r'\\D', '', regex=True)  # Remove non-numeric characters\n",
    "df['Phone Number'] = df['Phone Number'].str.replace(r'(\\d{3})(\\d{3})(\\d{4})', r'(\\1) \\2-\\3', regex=True)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation\n",
    "\n",
    "In this code, we first remove all non-numeric characters from the phone number column. Then, we apply a consistent format, '(XXX) XXX-XXXX', to all entries. This ensures that all phone numbers follow the same format, making them easier to analyze and compare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.2.2 Correcting Typos\n",
    "\n",
    "Typos are common data entry errors, especially when data is manually entered. Correcting these typos involves identifying and fixing common spelling mistakes or incorrect entries in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Product ID Product Name\n",
      "0           1     Widget A\n",
      "1           2     Widget B\n",
      "2           3     Widget C\n",
      "3           4     Widget D\n",
      "4           5     Widget E\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample Data\n",
    "data = {'Product ID': [1, 2, 3, 4, 5],\n",
    "        'Product Name': ['Widget A', 'Widgit B', 'Widget C', 'Widdget D', 'Widget E']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Correcting Typos\n",
    "typo_corrections = {'Widgit B': 'Widget B', 'Widdget D': 'Widget D'}\n",
    "df['Product Name'] = df['Product Name'].replace(typo_corrections)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation\n",
    "\n",
    "In this example, we define a dictionary of common typos and their correct versions. We then use the replace method to correct these typos in the Product Name column. This ensures that all product names are consistent and free of errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.2.3 Handling Inconsistent Data\n",
    "\n",
    "Inconsistent data entries can arise when different formats or naming conventions are used for the same data. Handling these inconsistencies involves standardizing the data so that it is uniform throughout the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Product ID     Category\n",
      "0           1  electronics\n",
      "1           2  electronics\n",
      "2           3  electronics\n",
      "3           4   home goods\n",
      "4           5   home goods\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample Data\n",
    "data = {'Product ID': [1, 2, 3, 4, 5],\n",
    "        'Category': ['electronics', 'Electronics', 'ELECTRONICS', 'home goods', 'Home Goods']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Standardizing Categories\n",
    "df['Category'] = df['Category'].str.lower()  # Convert all entries to lowercase\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation\n",
    "This code converts all entries in the Category column to lowercase, ensuring consistency. By standardizing the text case, we eliminate discrepancies caused by variations in capitalization, making the data easier to analyze."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.2.4 Validation Checks\n",
    "\n",
    "Validation checks involve applying rules or constraints to the data to ensure that entries are valid and meet specified criteria. These checks help to catch and correct errors during data entry or processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Product ID  Price\n",
      "0           1  19.99\n",
      "1           2  29.99\n",
      "2           3  15.00\n",
      "3           4  49.99\n",
      "4           5   9.99\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample Data\n",
    "data = {'Product ID': [1, 2, 3, 4, 5],\n",
    "        'Price': [19.99, -29.99, 15.00, 49.99, -9.99]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Validation Check: Ensuring Prices are Positive\n",
    "df['Price'] = df['Price'].apply(lambda x: abs(x) if x < 0 else x)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation\n",
    "\n",
    "In this code, we apply a validation check to ensure that all prices are positive. If a price is negative, we convert it to its absolute value. This simple check helps to prevent incorrect or misleading data entries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.2.5 Automated Data Correction\n",
    "\n",
    "Automated data correction involves using algorithms or machine learning models to automatically detect and correct data entry errors. This technique can be particularly useful for large datasets where manual correction is impractical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Product ID  Price\n",
      "0           1  19.99\n",
      "1           2  29.99\n",
      "2           3  29.99\n",
      "3           4  49.99\n",
      "4           5   9.99\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Sample Data\n",
    "data = {'Product ID': [1, 2, 3, 4, 5],\n",
    "        'Price': [19.99, 29.99, 1500.00, 49.99, 9.99]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Automated Data Correction using Isolation Forest\n",
    "iso = IsolationForest(contamination=0.1)\n",
    "outliers = iso.fit_predict(df[['Price']])\n",
    "df['Price'] = df['Price'].where(outliers == 1, df['Price'].median())\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation\n",
    "\n",
    "In this example, we use the Isolation Forest algorithm to detect outliers in the Price column. If an outlier is detected (e.g., an unusually high price), we replace it with the median price. This automated correction helps to address extreme or erroneous values that could skew the analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
